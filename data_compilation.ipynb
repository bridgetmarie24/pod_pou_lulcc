{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_compilation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOjdLdRzLGT73AEF8F4ALsX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Compile pre-processing outputs into one file**\n","\n","By Bridget Bittmann\n","\n","Date created: 04/04/2022\n","\n","Date modified: 06/01/2022"],"metadata":{"id":"bYPQ0sdMguzq"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"0fYb2dkrd2JV","executionInfo":{"status":"ok","timestamp":1655830541115,"user_tz":360,"elapsed":612,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"outputs":[],"source":["## --------------- ##\n","## IMPORT PACKAGES ## \n","## --------------- ##\n","\n","import pandas as pd # to work with dataframe\n","import os # for file paths\n","import glob # read in a folder of csv\n","import numpy as np # basic statistics\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20630,"status":"ok","timestamp":1655830561735,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"},"user_tz":360},"id":"NYmVxKSWeRUX","outputId":"47eda614-be75-469c-c00f-c545a4736332"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":513,"status":"ok","timestamp":1655830562210,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"},"user_tz":360},"id":"HmktJEieewNB","outputId":"d13b7ebc-6a32-4f95-d7be-94a0b5a602fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/spatial_colab/datasets\n","\u001b[0m\u001b[01;34mclimate_stats\u001b[0m/         \u001b[01;34mirrigation_companies\u001b[0m/  \u001b[01;34mlcmap_files\u001b[0m/   \u001b[01;34msubset_test_shp\u001b[0m/\n","\u001b[01;34mdiversion_timeseries\u001b[0m/  \u001b[01;34mirrig_lbrb\u001b[0m/            \u001b[01;34mmasked\u001b[0m/\n","\u001b[01;34mextra_figures\u001b[0m/         \u001b[01;34mIrrMapper\u001b[0m/             \u001b[01;34moutput_files\u001b[0m/\n","\u001b[01;34mhydromet_data\u001b[0m/         \u001b[01;34mLBRB_shp\u001b[0m/              \u001b[01;34mPOUs\u001b[0m/\n"]}],"source":["## NAVIGATE TO YOUR DIRECTORY ##\n","%cd gdrive/MyDrive/spatial_colab/datasets/\n","%ls"]},{"cell_type":"code","source":["## -------------------- ##\n","## IMOPORT ALL DATASETS ##\n","## -------------------- ##\n","\n","div_files = sorted(glob.glob('diversion_timeseries/final_stats/*.csv'))\n","land_files = sorted(glob.glob('lcmap_files/final_metrics/*.csv'))\n","climate_files = sorted(glob.glob('climate_stats/final/*.csv'))\n","hydromet = pd.read_csv('hydromet_data/mode_input_hydromet.csv')\n","common_name_flow = pd.read_csv('diversion_timeseries/relates/name_dictionary_flow.csv')\n","common_name_spatial = pd.read_csv('diversion_timeseries/relates/name_dictionary_spatial.csv')"],"metadata":{"id":"xPt2rGYjt5DF","executionInfo":{"status":"ok","timestamp":1655830565676,"user_tz":360,"elapsed":3470,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["## --------------------------------- ##\n","## CREATE COMMON NAME TO MERGE FILES ## \n","## --------------------------------- ##\n","\n","# Import discharge data \n","\n","div_data = []\n","for i in div_files:\n","  discharge = pd.read_csv(i)\n","  discharge['DiversionName_x'] = discharge['DiversionName_x'].str.replace(r\"\\(.*\\)\", \"\")\n","  div_data.append(discharge)\n","\n","div = pd.concat(div_data).drop_duplicates('Unnamed: 0', keep='first')\n","# Dicharge data dictionary\n","\n","div_dict = dict(zip(common_name_flow['DiversionName'], common_name_flow['NewName']))\n","div['Name'] = div['DiversionName_x'].map(div_dict)\n","div = div.drop(['Unnamed: 0', 'DiversionName_x', 'CFS'], axis=1)\n","display(div)\n","\n","# Import land use change data\n","\n","land_data = []\n","for i in land_files:\n","  land_data.append(pd.read_csv(i))\n","\n","land = pd.concat(land_data)\n","\n","# Land use dictionary\n","\n","shape_dict = dict(zip(common_name_spatial['WaterRight'], common_name_spatial['NewName']))\n","land['Name'] = land['DivName'].map(shape_dict)\n","land = land.dropna().drop(['Unnamed: 0', 'DivName'], axis=1)\n","\n","# Import climate zonal stats\n","\n","clim_data = []\n","for i in climate_files:\n","  clim_data.append(pd.read_csv(i))\n","clim = pd.concat(clim_data)\n","\n","# Use shapefile dictionary on climate data\n","\n","clim['Name'] = clim['DIV_NAME'].map(shape_dict)\n","clim = clim.dropna().drop(['Unnamed: 0', 'DIV_NAME'], axis=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":801},"id":"M9yxSzfYu9iH","executionInfo":{"status":"ok","timestamp":1655831728988,"user_tz":360,"elapsed":1518,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}},"outputId":"af00d4be-15fb-4a36-ad98-05e5ef90daf5"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n","  # Remove the CWD from sys.path while we load stuff.\n"]},{"output_type":"display_data","data":{"text/plain":["      Year  Diversion (cfs)    Acre_feet   Month  DayofYear  \\\n","0     1988           1617.5  3208.271828  2384.0    67161.0   \n","1     1989           1792.0  3554.388325  2382.0    66795.0   \n","2     1990           1836.5  3642.652990  2382.0    66795.0   \n","3     1991           3021.0  5992.079872  2382.0    66795.0   \n","4     1992           1951.0  3869.760950  2384.0    67161.0   \n","...    ...              ...          ...     ...        ...   \n","1844  1990           1003.0  1989.426055  2382.0    66795.0   \n","1845  1989           1092.0  2165.955386  2382.0    66795.0   \n","1846  1988           1157.5  2295.873039  2384.0    67161.0   \n","1847  1996            647.1  1283.507079  2384.0    67161.0   \n","1848  2001            827.5  1641.326082  2382.0    66795.0   \n","\n","                StartDate  StartDayofYear              EndDate  EndDayofYear  \\\n","0              1988-04-21             112           1988-10-20           294   \n","1              1989-04-20             110           1989-10-10           283   \n","2              1990-04-19             109           1990-10-14           287   \n","3              1991-04-10             100           1991-10-15           288   \n","4              1992-04-08              99           1992-10-30           304   \n","...                   ...             ...                  ...           ...   \n","1844  1990-04-04 00:00:00              94  1990-10-14 00:00:00           287   \n","1845  1989-04-11 00:00:00             101  1989-10-08 00:00:00           281   \n","1846  1988-04-01 00:00:00              92  1988-10-02 00:00:00           276   \n","1847  1996-04-30 00:00:00             121  1996-10-15 00:00:00           289   \n","1848  2001-04-09 00:00:00              99  2001-10-14 00:00:00           287   \n","\n","      Range                Name  \n","0       182             Andrews  \n","1       173             Andrews  \n","2       178             Andrews  \n","3       188             Andrews  \n","4       205             Andrews  \n","...     ...                 ...  \n","1844    193  Warm Springs Canal  \n","1845    180  Warm Springs Canal  \n","1846    184  Warm Springs Canal  \n","1847    168  Warm Springs Canal  \n","1848    188  Warm Springs Canal  \n","\n","[1849 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-2a3a7b9b-3214-4b44-a5e8-f7eb125fa803\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Year</th>\n","      <th>Diversion (cfs)</th>\n","      <th>Acre_feet</th>\n","      <th>Month</th>\n","      <th>DayofYear</th>\n","      <th>StartDate</th>\n","      <th>StartDayofYear</th>\n","      <th>EndDate</th>\n","      <th>EndDayofYear</th>\n","      <th>Range</th>\n","      <th>Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1988</td>\n","      <td>1617.5</td>\n","      <td>3208.271828</td>\n","      <td>2384.0</td>\n","      <td>67161.0</td>\n","      <td>1988-04-21</td>\n","      <td>112</td>\n","      <td>1988-10-20</td>\n","      <td>294</td>\n","      <td>182</td>\n","      <td>Andrews</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1989</td>\n","      <td>1792.0</td>\n","      <td>3554.388325</td>\n","      <td>2382.0</td>\n","      <td>66795.0</td>\n","      <td>1989-04-20</td>\n","      <td>110</td>\n","      <td>1989-10-10</td>\n","      <td>283</td>\n","      <td>173</td>\n","      <td>Andrews</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1990</td>\n","      <td>1836.5</td>\n","      <td>3642.652990</td>\n","      <td>2382.0</td>\n","      <td>66795.0</td>\n","      <td>1990-04-19</td>\n","      <td>109</td>\n","      <td>1990-10-14</td>\n","      <td>287</td>\n","      <td>178</td>\n","      <td>Andrews</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1991</td>\n","      <td>3021.0</td>\n","      <td>5992.079872</td>\n","      <td>2382.0</td>\n","      <td>66795.0</td>\n","      <td>1991-04-10</td>\n","      <td>100</td>\n","      <td>1991-10-15</td>\n","      <td>288</td>\n","      <td>188</td>\n","      <td>Andrews</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1992</td>\n","      <td>1951.0</td>\n","      <td>3869.760950</td>\n","      <td>2384.0</td>\n","      <td>67161.0</td>\n","      <td>1992-04-08</td>\n","      <td>99</td>\n","      <td>1992-10-30</td>\n","      <td>304</td>\n","      <td>205</td>\n","      <td>Andrews</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1844</th>\n","      <td>1990</td>\n","      <td>1003.0</td>\n","      <td>1989.426055</td>\n","      <td>2382.0</td>\n","      <td>66795.0</td>\n","      <td>1990-04-04 00:00:00</td>\n","      <td>94</td>\n","      <td>1990-10-14 00:00:00</td>\n","      <td>287</td>\n","      <td>193</td>\n","      <td>Warm Springs Canal</td>\n","    </tr>\n","    <tr>\n","      <th>1845</th>\n","      <td>1989</td>\n","      <td>1092.0</td>\n","      <td>2165.955386</td>\n","      <td>2382.0</td>\n","      <td>66795.0</td>\n","      <td>1989-04-11 00:00:00</td>\n","      <td>101</td>\n","      <td>1989-10-08 00:00:00</td>\n","      <td>281</td>\n","      <td>180</td>\n","      <td>Warm Springs Canal</td>\n","    </tr>\n","    <tr>\n","      <th>1846</th>\n","      <td>1988</td>\n","      <td>1157.5</td>\n","      <td>2295.873039</td>\n","      <td>2384.0</td>\n","      <td>67161.0</td>\n","      <td>1988-04-01 00:00:00</td>\n","      <td>92</td>\n","      <td>1988-10-02 00:00:00</td>\n","      <td>276</td>\n","      <td>184</td>\n","      <td>Warm Springs Canal</td>\n","    </tr>\n","    <tr>\n","      <th>1847</th>\n","      <td>1996</td>\n","      <td>647.1</td>\n","      <td>1283.507079</td>\n","      <td>2384.0</td>\n","      <td>67161.0</td>\n","      <td>1996-04-30 00:00:00</td>\n","      <td>121</td>\n","      <td>1996-10-15 00:00:00</td>\n","      <td>289</td>\n","      <td>168</td>\n","      <td>Warm Springs Canal</td>\n","    </tr>\n","    <tr>\n","      <th>1848</th>\n","      <td>2001</td>\n","      <td>827.5</td>\n","      <td>1641.326082</td>\n","      <td>2382.0</td>\n","      <td>66795.0</td>\n","      <td>2001-04-09 00:00:00</td>\n","      <td>99</td>\n","      <td>2001-10-14 00:00:00</td>\n","      <td>287</td>\n","      <td>188</td>\n","      <td>Warm Springs Canal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1849 rows × 11 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a3a7b9b-3214-4b44-a5e8-f7eb125fa803')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2a3a7b9b-3214-4b44-a5e8-f7eb125fa803 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2a3a7b9b-3214-4b44-a5e8-f7eb125fa803');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["## -------------------------------------- ## \n","## MERGE DIVERSION DATA TO MATCH THE POUS ## \n","## -------------------------------------- ## \n","\n","\n","# Create function to do this\n","\n","def merge_flows(data, name):\n","  '''\n","  This function will merge two different flow datasets into one for completely overlapping POUs.\n","\n","  Variables:\n","  data : The full diversion dataset\n","  name : A string of the new name for each POU.\n","  '''\n","  old_df = data[data['Name']== name].reset_index().drop('index', axis=1)\n","  new_df = pd.DataFrame()\n","  new_df['Year'] = old_df['Year'].unique()\n","  new_df['Name'] = old_df['Name'][0:34]\n","  sums = old_df.groupby('Year').sum().reset_index()\n","  new_df['Diversion (cfs)'] = sums['Diversion (cfs)']\n","  new_df['Acre_feet'] = sums['Acre_feet']\n","\n","  startday = []\n","  start_date = []\n","  endday = []\n","  range = []\n","  end_date = []\n","\n","  for i in new_df['Year']:\n","    yearly = old_df[old_df['Year'] == i]\n","    start = np.min(yearly['StartDayofYear'].values)\n","    startdate = yearly['StartDate'][yearly['StartDayofYear']==start].values\n","    end = np.max(yearly['EndDayofYear'].values)\n","    enddate = yearly['EndDate'][yearly['EndDayofYear']==end].values\n","    startday.append(start)\n","    endday.append(end)\n","    range.append(end-start)\n","    start_date.append(startdate[0])\n","    end_date.append(enddate[0])\n","\n","  new_df['StartDate'] = start_date\n","  new_df['StartDayofYear'] = startday\n","  new_df['EndDate'] = end_date\n","  new_df['EndDayofYear'] = endday\n","  new_df['Range'] = range\n","\n","  return new_df"],"metadata":{"id":"GI4RA6_iVuIu","executionInfo":{"status":"ok","timestamp":1655831770278,"user_tz":360,"elapsed":193,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["## ------------------------------------- ##\n","## MERGE DIVERSION DATASET WITH NEW DATA ##\n","## ------------------------------------- ##\n","\n","# Create a list of names that have completely shared POUs\n","merge_names = ['Shipley and Wagner Pumps', 'Rossi Mill and Meeves Canal', 'Boise City Parks']\n","\n","merged = []\n","for i in merge_names:\n","  new = merge_flows(div, i)\n","  div = div[div['Name'] != i] #Remove old dataframes from full dataset\n","  div = pd.concat([div, new])\n","  merged.append(new)\n","\n","div = div.sort_values(by=['Name', 'Year']).reset_index().drop('index',axis=1)"],"metadata":{"id":"7QnLnDRrW4lR","executionInfo":{"status":"ok","timestamp":1655831773708,"user_tz":360,"elapsed":158,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["## ------------------------------- ## \n","## MERGE THREE FILES INTO ONE FILE ##\n","## ------------------------------- ## \n","\n","land_div = div.merge(land, left_on=['Year', 'Name'], right_on=['dates','Name'], how='left')\n","full_df = land_div.merge(clim, left_on=['Year','Name'], right_on=['Year', 'Name'], how='left').sort_values(by=['Name', 'Year'])\n","full_df = full_df.merge(hydromet, left_on='Year', right_on='Year', how='left').drop(['Unnamed: 0', 'dates'], axis=1)\n","\n","## --------------------------------------- ##\n","## Export the full csv file for model in R ##\n","## --------------------------------------- ## \n","\n","# Full dataframe export\n","out_path = 'output_files/merged/model_input.csv'\n","full_df.to_csv(out_path)\n","\n","# Individual dataframe export\n","\n","names = full_df['Name'].unique()\n","for i in names:\n","  df = full_df[full_df['Name'] == i]\n","  out_path = os.path.join('output_files/'+i+'.csv')\n","  df.to_csv(out_path)"],"metadata":{"id":"xfC-BYJJtULS","executionInfo":{"status":"ok","timestamp":1655831808093,"user_tz":360,"elapsed":32072,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"execution_count":41,"outputs":[]}]}