{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_compilation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP04PCI9lmQ/I2R4G8bH6Jy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Compile pre-processing outputs into one file**\n","\n","By Bridget Bittmann\n","\n","Date created: 04/04/2022\n","\n","Date modified: 04/04/2022"],"metadata":{"id":"bYPQ0sdMguzq"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"0fYb2dkrd2JV","executionInfo":{"status":"ok","timestamp":1653491444954,"user_tz":360,"elapsed":781,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"outputs":[],"source":["import pandas as pd\n","import os \n","import glob\n","import numpy as np\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2621,"status":"ok","timestamp":1653491447568,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"},"user_tz":360},"id":"NYmVxKSWeRUX","outputId":"bb7f7f6e-5862-42e4-c987-465a9741682b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1653491447779,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"},"user_tz":360},"id":"HmktJEieewNB","outputId":"16c5869e-b861-4f55-917c-1378d5d8b4eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/spatial_colab/datasets\n"," \u001b[0m\u001b[01;34mclimate_stats\u001b[0m/                         \u001b[01;34mmasked\u001b[0m/\n"," \u001b[01;34mdiversion_timeseries\u001b[0m/                 'New York Canal_land_change.png'\n","'Farmers Union Canal_land_change.png'   ny_change.png\n"," fu_change.png                          \u001b[01;34moutput_files\u001b[0m/\n"," \u001b[01;34mhydromet_data\u001b[0m/                         \u001b[01;34mPOUs\u001b[0m/\n"," \u001b[01;34mirrigation_companies\u001b[0m/                  seb_change.png\n"," \u001b[01;34mirrig_lbrb\u001b[0m/                           'Sebree Canal_land_change.png'\n"," \u001b[01;34mIrrMapper\u001b[0m/                             set_change.png\n"," \u001b[01;34mLBRB_shp\u001b[0m/                             'Settlers Canal_land_change.png'\n"," \u001b[01;34mlcmap_files\u001b[0m/                           \u001b[01;34msubset_test_shp\u001b[0m/\n"]}],"source":["## NAVIGATE TO YOUR DIRECTORY ##\n","%cd gdrive/MyDrive/spatial_colab/datasets/\n","%ls"]},{"cell_type":"code","source":["## ------------------- ##\n","## IMPORT ALL DATASETS ##\n","## ------------------- ##\n","\n","div_files = sorted(glob.glob('diversion_timeseries/final_stats/*.csv'))\n","land_files = sorted(glob.glob('lcmap_files/proportions/longform_proportions/*.csv'))\n","climate_files = sorted(glob.glob('climate_stats/final/*.csv'))\n","hydromet = pd.read_csv('hydromet_data/mode_input_hydromet.csv')\n","common_name = pd.read_csv('diversion_timeseries/relates/name_dictionary.csv')\n","\n","## Clean the dataframes to match by renaming to create a common name among all three datasets\n","\n","div_data = []\n","for i in div_files:\n","  div = pd.read_csv(i)\n","  div['DiversionName_x'] = div['DiversionName_x'].str.replace(r\"\\(.*\\)\", \"\")\n","  if common_name['DiversionName'].str.contains(div['DiversionName_x'][0]).any():\n","    div['DiversionName_x'] = common_name['NewName'][common_name['DiversionName'].str.contains(div['DiversionName_x'][0])].to_string(index=False)\n","    div = div.drop(labels='Unnamed: 0', axis=1)\n","    div = div.rename(columns={'DiversionName_x':'DiversionName'})\n","    div_data.append(div)\n","  else:\n","    None\n","\n","div_data = div_data[0:65]\n","div = pd.concat(div_data)\n","\n","land_data = []\n","for i in land_files:\n","  land = pd.read_csv(i)\n","  new_name = common_name['NewName'][common_name['WaterRight'].str.contains(land['DivName'][0])].reset_index()\n","  new_name = new_name['NewName'][0]\n","  land['DivName'] = new_name\n","  land = land.drop(labels='Unnamed: 0', axis=1)\n","  land = land.drop(axis=0, index=[0,1]).reset_index().drop(labels=['index'], axis=1)\n","  land = land.rename(columns={'DivName':'DiversionName'})\n","  land_data.append(land)\n","\n","\n","land = pd.concat(land_data)\n","\n","\n","climate_data = []\n","for i in climate_files:\n","  clim = pd.read_csv(i)\n","  new_name = common_name['NewName'][common_name['WaterRight'].str.contains(clim['DIV_NAME'][0])].reset_index()\n","  new_name = new_name['NewName'][0]\n","  clim['DIV_NAME'] = new_name\n","  clim = clim.drop(labels=['Unnamed: 0'], axis=1).reset_index().drop(labels=['index'], axis=1)\n","  clim = clim.rename(columns={'DIV_NAME':'DiversionName'})\n","  climate_data.append(clim)\n","\n","clim = pd.concat(climate_data)\n","\n","# ## Check to make sure all the same length\n","print(len(common_name), len(div_data), len(land_data), len(climate_data))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwSii5MQhbBv","executionInfo":{"status":"ok","timestamp":1653491462074,"user_tz":360,"elapsed":14297,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}},"outputId":"d65e278b-06de-44d4-ab5d-c3c61c330dbe"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n","  app.launch_new_instance()\n"]},{"output_type":"stream","name":"stdout","text":["65 65 64 64\n"]}]},{"cell_type":"code","source":["## -------------------------------------- ## \n","## MERGE DIVERSION DATA TO MATCH THE POUS ## \n","## -------------------------------------- ## \n","\n","ship_wag = div[div['DiversionName']=='Shipley and Wagner Pumps']\n","new_ship_wag = pd.DataFrame()\n","new_ship_wag['Year'] = ship_wag['Year'].unique()\n","new_ship_wag['DiversionName'] = ship_wag['DiversionName'][0:34]\n","sums = ship_wag.groupby('Year').sum().reset_index()\n","new_ship_wag['CFS'] = sums['CFS']\n","new_ship_wag['Acre_feet'] = sums['Acre_feet']\n","\n","startday = []\n","start_date = []\n","endday = []\n","range = []\n","end_date = []\n","\n","for i in new_ship_wag['Year']:\n","  yearly = ship_wag[ship_wag['Year'] == i]\n","  start = np.min(yearly['StartDayofYear'].values)\n","  startdate = yearly['StartDate'][yearly['StartDayofYear']==start].values\n","  end = np.max(yearly['EndDayofYear'].values)\n","  enddate = yearly['EndDate'][yearly['EndDayofYear']==end].values\n","  startday.append(start)\n","  endday.append(end)\n","  range.append(end-start)\n","  start_date.append(startdate[0])\n","  end_date.append(enddate[0])\n","\n","new_ship_wag['StartDate'] = start_date\n","new_ship_wag['StartDayofYear'] = startday\n","new_ship_wag['EndDate'] = end_date\n","new_ship_wag['EndDayofYear'] = endday\n","new_ship_wag['Range'] = range\n","\n","#Remove old dataframes from full dataset\n","div = div[div['DiversionName'] != str(ship_wag['DiversionName'][2].values)]"],"metadata":{"id":"sL0XB9wDhh4N","executionInfo":{"status":"ok","timestamp":1653491462075,"user_tz":360,"elapsed":15,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## ------------------------------------- ##\n","## MERGE DIVERSION DATASET WITH NEW DATA ##\n","## ------------------------------------- ##\n","\n","div = pd.concat([div, new_ship_wag]).sort_values(by='DiversionName').reset_index().drop('index', axis=1)"],"metadata":{"id":"bhYvZPX1o-lK","executionInfo":{"status":"ok","timestamp":1653491462275,"user_tz":360,"elapsed":213,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["## ------------------------------- ## \n","## MERGE THREE FILES INTO ONE FILE ##\n","## ------------------------------- ## \n","\n","land_div = div.merge(land, left_on=['Year', 'DiversionName'], right_on=['dates','DiversionName'], how='left')\n","full_df = land_div.merge(clim, left_on=['Year','DiversionName'], right_on=['Year', 'DiversionName'], how='left').sort_values(by=['DiversionName', 'Year'])\n","full_df = full_df.merge(hydromet, left_on='Year', right_on='Year', how='left').drop(['Unnamed: 0', 'dates'], axis=1)\n","\n","## --------------------------------------- ##\n","## Export the full csv file for model in R ##\n","## --------------------------------------- ## \n","\n","# Full dataframe export\n","out_path = 'output_files/merged/model_input.csv'\n","full_df.to_csv(out_path)\n","\n","# Individual dataframe export\n","\n","names = full_df['DiversionName'].unique()\n","for i in names:\n","  df = full_df[full_df['DiversionName'] == i]\n","  out_path = os.path.join('output_files/'+i+'.csv')\n","  df.to_csv(out_path)"],"metadata":{"id":"xfC-BYJJtULS","executionInfo":{"status":"ok","timestamp":1653491462953,"user_tz":360,"elapsed":681,"user":{"displayName":"Bridget Bittmann","userId":"07833657036831444235"}}},"execution_count":7,"outputs":[]}]}