{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO50xig9Bhq/o3xZzdEwpTW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lJPS6NaM0VgI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fR_F_QA6Niju"},"outputs":[],"source":["## ------------------------------ ##\n","## SUBSET GEOSPATIAL DATA TO BPBC ##\n","## ------------------------------ ##\n","\n","shp_file = gpd.read_file('subset_test_shp/BPBC_Divisions/BPBC_Divisions-IDTM.shp') #open shapefile\n","names = shp_file['DivisionNa']\n","files = glob.glob('lcmap_files/*.tiff') #get all the years of cdl imagery\n","data =[]\n","for i in range(len(files)):\n","  data.append(rso.open(files[i])) #open cdl image and append to a list\n","shp = shp_file.to_crs(data[1].crs) #reproject the shp file to same projection\n","years = np.arange(1987, 2021) #years of LCMAP data\n","collection = []\n","for i in range(len(shp)):\n","  for n in range(len(years)):\n","    dataset = data[n]\n","    year_out = dataset.name[21:-15]\n","    extent = gpd.GeoSeries(shp['geometry'][i]) #get the geometry from shapefile\n","    coords = [json.loads(extent.to_json())['features'][0]['geometry']] #gets coordinates for rasterio input\n","    out_img, out_transform = mask(dataset=data[n], shapes=coords, crop=True, nodata=0) #crop the data to the shapefile\n","    out_meta = data[n].meta.copy()\n","    out_meta.update({\"driver\": \"GTiff\",\n","                     \"height\": out_img.shape[1],\n","                     \"width\": out_img.shape[2],\n","                     \"transform\": out_transform})\n","    # Merge original file name with init_landcover to denote that it is the initial land cover data for Janus\n","    in_file = files[n]\n","    out_filename = os.path.join('lcmap_files/lcmap_masked_bpbc/'+names[i]+'_'+year_out+'.tif') #create a file name to export to\n","    # Save clipped land cover coverage THIS WILL OVERWRITE FILES\n","    out_tiff = rso.open(out_filename, 'w', **out_meta)\n","    out_tiff.write(np.squeeze(out_img, 0), 1)\n","    out_tiff.close()\n","    collection.append(out_img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhWZbdMdOh-j"},"outputs":[],"source":["## ---------------------------------------- ##\n","## Import multiple rasters into PyLandStats ##\n","## ---------------------------------------- ##\n","years = np.arange(1987,2021)\n","temporal_group = []\n","for i in range(len(names)):\n","  files= sorted(glob.glob('lcmap_files/lcmap_masked_bpbc/'+names[i]+'_*.tif')) #name for all the csv files\n","  sta = SpatioTemporalAnalysis(files, dates=years, nodata=0) #import all CDL rasters and mask\n","  temporal_group.append(sta)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BnJz-yl9PZKc"},"outputs":[],"source":["# ------------------------------------ #\n","# CALCULATE THE CLASS PROPORTIONS BPBC #\n","# ------------------------------------ #\n","\n","proportions = []\n","\n","for i in range(len(names)):\n","  df = SpatioTemporalAnalysis.compute_class_metrics_df(temporal_group[i], metrics=['proportion_of_landscape'])\n","  df.to_csv('lcmap_files/proportions/bpbc_metrics/long/'+names[i]+'_prop.csv')\n","  proportions.append(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nwq0PZHTPI2J"},"outputs":[],"source":["# ------------------------------------ #\n","# CALCULATE CONFIGURATION METRICS BPBC #\n","# ------------------------------------ #\n","\n","config = []\n","\n","for i in range(len(names)):\n","  df = SpatioTemporalAnalysis.compute_landscape_metrics_df(temporal_group[i], metrics = ['contagion', 'largest_patch_index'])\n","  df.to_csv('lcmap_files/proportions/bpbc_metrics/long/'+names[i]+'_configuration.csv')\n","  config.append(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qNxufwk-P_iv"},"outputs":[],"source":["# ---------------------------------------------------------------------- #\n","# Put class proportions in the same format as configuration metrics BPBC #\n","# ---------------------------------------------------------------------- #\n","\n","# Import csv files into a list of dataframes\n","\n","files = sorted(glob.glob('lcmap_files/proportions/bpbc_metrics/long/*_prop.csv'))\n","files_config = sorted(glob.glob('lcmap_files/proportions/bpbc_metrics/long/*_configuration.csv'))\n","names = list(sorted(shp_file['DivisionNa']))\n","\n","proportions = []\n","for i in files:\n","  data = pd.read_csv(i)\n","  proportions.append(data)\n","config = []\n","for i in files_config:\n","  data = pd.read_csv(i)\n","  config.append(data)\n","\n","#Create new dataframes in same format as configuration metrics\n","\n","new_df = []\n","for i in range(len(proportions)):\n","  df = pd.DataFrame(years, columns=['dates'])\n","  prop = proportions[i]\n","  df['DivName'] = names[i]\n","  df['class1_urban'] = prop['proportion_of_landscape'][prop['class_val'] == 1]\n","  df['class2_crops'] = prop['proportion_of_landscape'][prop['class_val'] == 2].values\n","  df = df.fillna(0)\n","  new_df.append(df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHsWiLu8dgGn"},"outputs":[],"source":["## ----------------------------------------------- ##\n","## CALCULATE CHANGE IN URBAN AREA FOR MAPPING BPBC ##\n","## ----------------------------------------------- ##\n","\n","prop = pd.concat(new_df)\n","\n","change = prop.groupby('DivName', as_index=False).class1_urban.agg(['min','max']).reset_index().fillna(0)\n","change['urb_change'] = change['max']-change['min']\n","change.to_csv('lcmap_files/proportions/bpbc_change.csv')"]}]}